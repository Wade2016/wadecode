# Analysis of the DNA-Protein interface from data generated by nucplot and curves program
import matplotlib
import matplotlib.pyplot as plt
from matplotlib import gridspec
from natsort import natsorted, ns
#import mdtraj as md
import multiprocessing as mp
import pandas as pd
import numpy as np
import io, os, sys, time, tarfile
import zipfile
 
class InMemoryZip(object):
 
	def __init__(self):
		# Create the in-memory file-like object
		self.in_memory_zip = io.BytesIO()
 
	def appendFile(self, file_path, file_name=None):
		if file_name is None:
			p, fn = os.path.split(file_path)
		else:
			fn = file_name
 
		c = open(file_path, "rb").read()
		self.append(fn, c)
 
		return self
 
	def append(self, filename_in_zip, file_contents):
		"""Appends a file with name filename_in_zip and contents of
			file_contents to the in-memory zip."""
 
		# Get a handle to the in-memory zip in append mode
		zf = zipfile.ZipFile(self.in_memory_zip, "a", zipfile.ZIP_DEFLATED, False)
 
		# Write the file to the in-memory zip
		zf.writestr(filename_in_zip, file_contents)
 
		# Mark the files as having been created on Windows so that
		# Unix permissions are not inferred as 0000
		for zfile in zf.filelist:
			zfile.create_system = 0
		
		return self
 
 
	def read(self):
		"""Returns a string with the contents of the in-memory zip."""
		self.in_memory_zip.seek(0)
 		
		return self.in_memory_zip.read()
 
	def writetofile(self, filename):
		"""Writes the in-memory zip to a file."""
 
		f = open(filename, "wb")
		f.write(self.read())
		f.close()
 

def NUCPLOT_EXTRACT(file_idx):
	print(file_idx)
	iidx=0
	nucdata=pd.DataFrame(columns=["Frame", "P_resname", "P_chain", "P_resid", "P_atom", "D_resname", "D_chain", "D_resid", "D_atom", "Dist", "Type"])
	frame=int(file_idx.split('.')[0].split('_')[1])
	file_name=tarnucplot.extractfile(file_idx)
	Hbond=False
	Nbond=False
	#columns=["Frame", "P_resname", "P_chain", "P_resid", "P_atom", "D_resname", "D_chain", "D_resid", "D_atom", "Dist", "Typ")
	for line in file_name.readlines():
		sline=line.decode('ASCII')
		if sline.find("HIS") >= 0:
			print("FOUND HIS IN:", file_idx)
			sline=sline.replace("HIS", "HIE")
			print(sline)
		slist=sline.split()
		slength=len(slist)
		if (Hbond == True)  and  (slength > 0) :
			if (slength == 9) and (slist[0] != 'ACE') and (slist[0]!= 'NME') and (slist[0] != 'Pt') and (slist[0]!='AME') and (slist[0]!='AMF') and (slist[4] != 'ACE') and (slist[4]!= 'NME') and (slist[4] != 'Pt') and (slist[4]!='AME') and (slist[4]!='AMF'):
				#print('HBOND:', sline)
				#extract Hbonds
				if slist[1] != "B":
					slist[0:4],slist[4:8]=slist[4:8],slist[0:4]
					#print(slist)
				nucdata.loc[str(frame)+"_"+str(iidx)]={"Frame": frame, "P_resname": slist[0], "P_chain": slist[1], "P_resid":slist[2], "P_atom":slist[3], 
						"D_resname":slist[4], "D_chain":slist[5], "D_resid":slist[6], "D_atom":slist[7], "Dist":slist[8], "Type": "HB"}
				iidx=iidx+1
			if slist[0] == "protein" :
				#print("HBOND END, NBOND START")
				Nbond=True
				Hbond=False
		else:
			#print("finding:", slength)
			if slength > 0:
				if slist[0] == "Donor" :
					#print("found Hbond")
					Hbond=True
		if (Nbond == True) and (slength > 0) :
			if (slength == 9) and (slist[0] != 'ACE') and (slist[0]!= 'NME') and (slist[0] != 'Pt') and (slist[0]!='AME') and (slist[0]!='AMF') and (slist[4] != 'ACE') and (slist[4]!= 'NME') and (slist[4] != 'Pt') and (slist[4]!='AME') and (slist[4]!='AMF'):
				#extract NBOND
				#print('NBOND:', sline)
				bt="NB"
				if float(atom_pars.loc[str(slist[0]+"_"+slist[3])]['Charge']) * float(atom_pars.loc[str(slist[4]+"_"+slist[7])]['Charge']) < -1.0e-1 :
					#print("CHARGE:",atom_pars.loc[str(slist[0]+"_"+slist[3])]['Charge'],atom_pars.loc[str(slist[4]+"_"+slist[7])]['Charge'] )
					bt="IB"
				nucdata.loc[str(frame)+"_"+str(iidx)]={"Frame": frame, "P_resname": slist[0], "P_chain": slist[1], "P_resid":slist[2], "P_atom":slist[3], 
						"D_resname":slist[4], "D_chain":slist[5], "D_resid":slist[6], "D_atom":slist[7], "Dist":slist[8], "Type": bt}
				iidx=iidx+1

			if slist[0] == "****" :
				#print("NBOND END")
				Nbond=False
				break
	#write to InMemoryZip file
	#imz.append(str(frame)+"_tmpnuc.csv", nucdata.to_csv())
	nucdata.to_csv("."+file_idx+"_tmpnuc.csv")
	return frame

def ATOM_PAR(topfile):
	para=pd.DataFrame(columns=["Charge", "Mass"])
	CHOSE=False
	IDX=0
	i=0
	with open(topfile) as lines:
		for line in lines:
			sline=line.split()
			slength=len(sline)
			if slength > 1:
				#print(i, sline)
				if (IDX < 2) and (sline[1] == "moleculetype") :
					CHOSE=True
					IDX=IDX+1
					#print("FIND SECTION")
				else:
					if (slength == 11) and (CHOSE == True) and (sline[3] != 'NME') and (sline[3] != 'ACE') and (sline[3] != 'Pt' and (sline[3] != 'AME') and (sline[3] != 'AMF')):
						para.loc[str(sline[3]+"_"+sline[4])]={"Charge": sline[6], "Mass":sline[7]}
						i=i+1
						#print("READ SECTION")
					if sline[1] == "bonds":
						CHOSE=False
						#print("READ END")
	
	return para
			
def PTM_NEW(PDB):
	atom_aly=[]
	atom_lys=[]
	atom_sep=[]
	atom_ser=[]
	with open(PDB) as lines:
		for line in lines:
			sline=line.split()
			if(sline[0]=="ATOM" and sline[3]=="ALY"):
				atom_aly.append(sline[2])
			if(sline[0]=="ATOM" and sline[3]=="LYS"):
				atom_lys.append(sline[2])
			if(sline[0]=="ATOM" and sline[3]=="SEP"):
				atom_sep.append(sline[2])
			if(sline[0]=="ATOM" and sline[3]=="SER"):
				atom_ser.append(sline[2])
	atom_aly=set(atom_aly)
	atom_lys=set(atom_lys)
	atom_sep=set(atom_sep)
	atom_ser=set(atom_ser)
	
	aly_new=(atom_lys | atom_aly) - atom_lys
	sep_new=set(atom_sep | atom_ser) - atom_ser
	#print(atom_aly)
	#print(atom_lys)
	print(aly_new, sep_new)
	return aly_new, sep_new

def NCI_Classfication(filename, THsbi, THnic):
	NCI_data=pd.DataFrame.from_csv(filename)
	
	NCI_data=NCI_data
	# ref: nucdata=pd.DataFrame(columns=["Frame", "P_resname", "P_chain", "P_resid", "P_atom", "PA_charge", "D_resname", "D_chain", "D_resid", "D_atom", "DA_charge", "Dist", "Evdw", "Ecoul", "Type"])

	############################################################
	# Check if the non-bond energy of atompairs already calculated or not
#	if "Enonb" in NCI_data.columns:
#		print("Enonb has been calculated in previous step! \n Our life is easier now!")
#	else:
	#NCI_data["Enonb"]=NCI_data["Evdw"]+NCI_data["Ecoul"] # make sure distance is in nm
	#print("Enonb:", NCI_data[0]["Evdw"],NCI_data[0]["Ecoul"],NCI_data[0]["Enonb"])
	#print("Enonb has been added to Dataframe")
	############################################################

	############################################################
	# Mark the PTMs and re-name their resname
	P_name=NCI_data[["P_resname","P_atom"]]
	ALY = P_name.where(P_name["P_resname"] == "ALY")
	SEP = P_name.where(P_name["P_resname"] == "SEP")
	only_ALY=ALY.dropna()
	only_SEP=SEP.dropna()
	ALY_ptm = [(only_ALY.loc[idx]["P_atom"] in ptm_aly) for idx in only_ALY.index]
	SEP_ptm = [(only_SEP.loc[idx]["P_atom"] in ptm_sep) for idx in only_SEP.index]
	print(ALY_ptm[0:10])
	only_ALY["ptm"] = pd.Series(ALY_ptm, index=only_ALY.index)
	only_SEP["ptm"] = pd.Series(SEP_ptm, index=only_SEP.index)
	only_ALY=only_ALY[only_ALY.ptm]
	only_SEP=only_SEP[only_SEP.ptm]

	PTM_IDX=list(only_ALY.index) + list(only_SEP.index)
	PTMA_IDX=only_ALY.index
	PTMP_IDX=only_SEP.index
	print("ALY+SEP:", PTM_IDX[0:10])
	print("PTM interaction:", len(PTM_IDX))
	print("ALL interaction:", len(NCI_data.index))
	#WT_IDX=[i for i in NCI_data.index if i not in PTM_IDX]
	WT_IDX=list(set(NCI_data.index)-set(PTM_IDX))
	print(WT_IDX[:10])
	print(len(WT_IDX))
	
	NCI_data["PTM"]=pd.DataFrame(index=PTM_IDX, columns=["PTM"])
	
	[(NCI_data.set_value(idx, "PTM", "AP")) for idx in PTMA_IDX]
	[(NCI_data.set_value(idx, "PTM", "PP")) for idx in PTMP_IDX]
	[(NCI_data.set_value(idx, "PTM", "WT")) for idx in WT_IDX]

	NCI_data.replace("ALY", "LYS",inplace=True)
	NCI_data.replace("SEP", "SER",inplace=True)
	print("PTMs annotation and resname correction are done!")
	############################################################

	############################################################
	# Finding out the Hbonding contacts (HBC)
	NCI_HBC=NCI_data[NCI_data.Type == "HB"]
	print("USEFUL: HBC:", NCI_HBC.shape,"HBC/ALL:", NCI_HBC.shape[0]/NCI_data.shape[0])
	NCI_HBC.to_csv("NCI_HBC.csv")
	[(NCI_data.set_value(idx, "HBC", "True"), NCI_data.set_value(idx, "Type", "HBC")) for idx in NCI_HBC.index]
	NCI_SUB0=NCI_data[NCI_data.HBC !="True"]
	NCI_SUB0.to_csv("test_sub0.csv")
	############################################################


	############################################################
	# Finding out the Salt Bridge Contacts(SBC)
	Pres, Dres, PTMres = NCI_SUB0["P_resname"], NCI_SUB0["D_resname"], NCI_SUB0.where(NCI_SUB0.PTM=="WT").fillna(0)["PTM"].values
	DresN=[(idx in negset) for idx in Dres]
	DresP=[(idx in posset) for idx in Dres]
	PresN=[(idx in negset) for idx in Pres]
	PresP=[(idx in posset) for idx in Pres]
	PTMresb=[bool(i) for i in PTMres]
	print("DNA_Positive:",DresP[:20])
	print("DNA_Negtive:",DresN[:20])
	print("Pro_Positive:",PresP[:20])
	print("Pro_Negtive:",PresN[:20])
	print("PTMres:",PTMres[:10])
	print("PTMresb:",PTMresb[:10])
	print("PresP:",PresP[:10])
	PresP0= list(np.array(PresP) & np.array(PTMresb))
	print("P_PTM:", PresP0[:20])
	#SBI_RES= (DresP and PresN) or (DresN and PresP)
	SBI_RES= list(np.array(DresN) & np.array(PresP0))

	print("P+N:", SBI_RES[:20])

	NCI_SUB0["SBI_RES"]=pd.DataFrame(SBI_RES, index=NCI_SUB0.index)
	
	print("SBI_RES",SBI_RES[0:10])

	NCI_SUB1=NCI_SUB0[NCI_SUB0.SBI_RES]

	print("SBI res:",NCI_SUB1.shape)

	# Considering the contacts between net charged groups
	Patom, Datom = NCI_SUB1["P_atom"], NCI_SUB1["D_atom"]
	PatmP=[(idx not in pbonset) for idx in Patom] # chose the side-chain atoms in Patoms
	DatmN=[(idx in negdnagro) for idx in Datom]   # chose the negative charged groups 

	SBI_GRO= list(np.array(PatmP) & np.array(DatmN))
	
	NCI_SUB1["SBI"]=pd.DataFrame(SBI_GRO, index=NCI_SUB1.index)
	NCI_SBI=NCI_SUB1[NCI_SUB1.SBI]
	#del NCI_SUB1["SBI_GRO"]
	print("SBI_GRO",NCI_SBI.shape)

	"""
	# consider the partial charge, be careful !!!
	Pachr, Dachr = NCI_SUB1["PA_charge"], NCI_SUB1["DA_charge"]
	PDCR = np.multiply(list(Pachr), list(Dachr))
	print(Pachr[0],Dachr[0], PDCR[0])
	SBI_CHR = PDCR <= THsbi
	
	print("SBI_CHR",SBI_CHR[0:10])

	NCI_SUB1["SBI"] = pd.Series(SBI_CHR, index=NCI_SUB1.index)
	NCI_SBI=NCI_SUB1[NCI_SUB1.SBI]
	del NCI_SBI["SBI_RES"]

	"""

	print("USEFUL: SBI:",NCI_SBI.shape,"SBI/ALL:", NCI_SBI.shape[0]/NCI_data.shape[0])
	NCI_SBI.to_csv("NCI_SBI.csv")
	del NCI_SUB0["SBI_RES"]

	[(NCI_data.set_value(idx, "SBC", "True"), NCI_data.set_value(idx, "Type", "SBC")) for idx in NCI_SBI.index]

	HBCSBI=natsorted(list(NCI_SBI.index) + list(NCI_HBC.index))
	print(HBCSBI[0:10])
	[NCI_data.set_value(idx, "Temp", "True") for idx in HBCSBI]
	NCI_SUB2=NCI_data[NCI_data.Temp !="True"]
	NCI_SUB2.to_csv("test_sub2.csv")
	del NCI_data["Temp"]
	############################################################	


	############################################################
	# Finding out the Pi-stacking contacts(STC)
	Pres, Patom, Datom=NCI_SUB2["P_resname"],NCI_SUB2["P_atom"],NCI_SUB2["D_atom"]
	Arores=[(idx in aroset) for idx in Pres]
	Arosc =[(idx in pbonset) for idx in Patom]
	NOTSC = [not i for i in Arosc]
	print("NOT AROSCH:", NOTSC[0:10])
	Dbase =[(not (idx in dbonset)) for idx in Datom]
	STC_RES= list(np.array(Arores) & np.array(NOTSC) & np.array(Dbase))
	
	NCI_SUB2["STC_RES"]=pd.DataFrame(STC_RES, index=NCI_SUB2.index)
	print("STC_RES",STC_RES[0:10])
	
	NCI_STC=NCI_SUB2[NCI_SUB2.STC_RES]
	print("USEFUL: STC:",NCI_STC.shape, "STC/ALL:", NCI_STC.shape[0]/NCI_data.shape[0])
	NCI_STC.to_csv("NCI_STC.csv")
	del NCI_SUB2["STC_RES"]
	
	[(NCI_data.set_value(idx, "STC", "True"), NCI_data.set_value(idx, "Type", "STC")) for idx in NCI_STC.index]

	HBCSBISTC=natsorted(list(NCI_STC.index) + list(NCI_SBI.index) + list(NCI_HBC.index))
	
	[NCI_data.set_value(idx, "Temp", "True") for idx in HBCSBISTC]
	NCI_SUB3=NCI_data[NCI_data.Temp !="True"]
	NCI_SUB3.to_csv("test_sub3.csv")
	print("SUB3:",NCI_SUB3.shape)
	del NCI_data["Temp"]
	############################################################

	############################################################
	# Finding out the hydrohobic interactions(HYC)
	Pres, Patom, Datom=NCI_SUB3["P_resname"], NCI_SUB3["P_atom"], NCI_SUB3["D_atom"]
	Hydres=[(idx in hydset) for idx in Pres]
	Hydsc =[(idx in pbonset) for idx in Patom]
	NOTSC = [not i for i in Hydsc]
	print("NOT HYDSCH:", NOTSC[0:10])
	Dbase =[(not (idx in dbonset)) for idx in Datom]
	HYD_RES= list(np.array(Hydres) & np.array(NOTSC) & np.array(Dbase))
	NCI_SUB3["HYD_RES"]=pd.DataFrame(HYD_RES, index=NCI_SUB3.index)
	print("HYD_RES",HYD_RES[0:10])
	NCI_HYD=NCI_SUB3[NCI_SUB3.HYD_RES]
	print("USEFUL: HYC:",NCI_HYD.shape, "HYC/ALL:", NCI_HYD.shape[0]/NCI_data.shape[0])
	NCI_HYD.to_csv("NCI_HYC.csv")
	del NCI_SUB3["HYD_RES"]

	[(NCI_data.set_value(idx, "HYC", "True"), NCI_data.set_value(idx, "Type", "HYC")) for idx in NCI_HYD.index]

	HBCSBISTCHYC=natsorted(list(NCI_STC.index) + list(NCI_SBI.index) + list(NCI_HBC.index) + list(NCI_HYD.index))
	[NCI_data.set_value(idx, "Temp", "True") for idx in HBCSBISTCHYC]
	NCI_SUB3=NCI_data[NCI_data.Temp !="True"]
	NCI_SUB3.to_csv("test_sub3hyd.csv")
	print("SUB3hyd:",NCI_SUB3.shape)
	del NCI_data["Temp"]

	# here I added the hyd type, but I still use sub3 because I don't want to change the following part. 

	############################################################
	# All other attractive interactions (Enonb<-1E-6) (AIC)
	Enonbond=NCI_SUB3["Enonb"]
	Aic= Enonbond < -1.0*THnic
	print("AIC:", Aic[0:10].values)
	NCI_SUB3["AIC"] = Aic
	##pd.Series(Aic, index=NCI_SUB3.index)
	NCI_AIC=NCI_SUB3[NCI_SUB3.AIC]
	del NCI_SUB3["AIC"]
	
	print("USEFUL: AIC:",NCI_AIC.shape,"AIC/ALL:", NCI_AIC.shape[0]/NCI_data.shape[0])

	NCI_AIC.to_csv("NCI_AIC.csv")
	
	[(NCI_data.set_value(idx, "AIC", "True"), NCI_data.set_value(idx, "Type", "AIC")) for idx in NCI_AIC.index]

	HBCSBISTCEACAIC=natsorted(list(NCI_SBI.index) + list(NCI_HBC.index) + list(NCI_STC.index)+ list(NCI_AIC.index))
	print(HBCSBISTCEACAIC[0:10])
	[NCI_data.set_value(idx, "Temp", "True") for idx in HBCSBISTCEACAIC]
	NCI_SUB4=NCI_data[NCI_data.Temp !="True"]
	print("sub4:",NCI_SUB4.shape)
	NCI_SUB4.to_csv("test_sub4.csv")
	del NCI_data["Temp"]
	####################################################################
	
	####################################################################
	# All other repulsive interactions (Ebon>1.e6) (RIC)
	Ric=Enonbond > THnic
	NCI_SUB4["RIC"]=pd.Series(Ric, index=NCI_SUB4.index)
	NCI_RIC=NCI_SUB4[NCI_SUB4.RIC]
	del NCI_SUB4["RIC"]
	
	print("USEFUL: RIC:",NCI_RIC.shape,"RIC/ALL:", NCI_RIC.shape[0]/NCI_data.shape[0])

	NCI_RIC.to_csv("NCI_RIC.csv")

	[(NCI_data.set_value(idx, "RIC", "True"), NCI_data.set_value(idx, "Type", "RIC")) for idx in NCI_RIC.index]

	HBCSBISTCEACAICRIC=natsorted(list(NCI_SBI.index) + list(NCI_HBC.index) + list(NCI_STC.index) + list(NCI_AIC.index)+ list(NCI_RIC.index))
	[NCI_data.set_value(idx, "Temp", "True") for idx in HBCSBISTCEACAICRIC]
	NCI_SUB5=NCI_data[NCI_data.Temp !="True"]
	print("sub5:",NCI_SUB5.shape)
	NCI_SUB5.to_csv("test_sub5.csv")
	del NCI_data["Temp"]
	#####################################################################
	# All other natural interactions (Enonb=0) (NIC)

	[(NCI_data.set_value(idx, "NIC", "True"), NCI_data.set_value(idx, "Type", "NIC")) for idx in NCI_SUB5.index]
	NCI_SUB5.to_csv("NCI_NIC.csv")

	print("USEFUL: NIC:",NCI_SUB5.shape,"NIC/ALL:", NCI_SUB5.shape[0]/NCI_data.shape[0])

	NCI_data.to_csv("Nucplot_classified.csv")

	return NCI_data

def Creat_Matrix(chunk):
	
	# Create a dataframe to store contactID matrix
        #NCI_contactID=pd.DataFrame(columns=ContactID)
        for frame in chunk:
                one_frame=NCI_data[NCI_data["Frame"]==frame]
                #print("Frame:", frame)
                [NCI_contactID.set_value(frame,one_frame.loc[idx]["Cname"], one_frame.loc[idx]["Dist"]) for idx in one_frame.index]
        print(NCI_contactID.shape)
        outid=os.getpid()
        NCI_contactID.to_csv(".NCI_contactID_"+str(outid), header=False)
        return outid

def Split_data(testlist):
        # split data set into the number of processors
        numproc = mp.cpu_count()-1
        numfile = len(testlist)
        setsize = int(numfile/numproc)
        resset  = numfile%numproc
        chunks  = [testlist[i:i+setsize] for i in range(0, numfile, setsize)]
        print("numproc:",numproc,"numfile:",numfile,"setsize:",setsize,"resset",resset)
        print("chunks:", len(chunks))
        return chunks

def Merge_data(outid, idfile, outfile):
	# Merge files to sigle file
	print("Merge data:")
	for i in natsorted(outid):
		print(i)
		os.system("cat "+ idfile + str(i) + " >> " + outfile)
	os.system("rm " + idfile+ "*")
	sdata=pd.DataFrame.from_csv(outfile)
	sdata=sdata.reindex(index=natsorted(sdata.index))
	sdata.to_csv(outfile)
	print(sdata.shape)
	return sdata
def map_pattern(colname, ptm, dataframe, level):
  #Attention, we must re-allocate memory for pattern DataFrame
  zeros_data=np.zeros([level+5, len(dataframe.columns)])
  pattern=pd.DataFrame(zeros_data, columns=dataframe.columns)
  for ic in range(len(pattern.columns)):
    tp = ord(list(ptm[ic])[0])
    print(tp,ptm[ic][0])
    for ir in range(level):
      if ir <= level*dataframe.loc[colname][ic]:
         pattern.set_value(pattern.index[ir], pattern.columns[ic] , tp)
    """
    if "ALY" in mty[ic]:
      pattern.set_value(pattern.index[level:level+5], pattern.columns[ic], 5)
    elif "SEP" in mty[ic]:
      pattern.set_value(pattern.index[level:level+5], pattern.columns[ic], 15)
    else:
      pattern.set_value(pattern.index[level:level+5], pattern.columns[ic], 20)
    """
  pattern.to_csv("pattern_"+colname+".csv")
  ptnew=pattern.where(pattern>0)
  ptnew.fillna(value=100)
  fig, ax = plt.subplots()

  #pdb.set_trace()
  #cmap = mpl.cm.get_cmap('PiYG', 10)
  cax = ax.imshow(ptnew)

  #cb  = mpl.colorbar.ColorbarBase(ax2, ticks=[80,78,72,67], boundaries=[60,70,80, 90], format='%1i') 
  #ax1.set_title(colname)
#  cbar=fig.colorbar(cax, ticks=[80,78,72,67], orientation='horizontal')
#  cbar.ax.set_yticklabels(['P','N','H','C'])
  plt.savefig("pattern_"+colname +".jpg")
  #plt.show()
  plt.close()
  return ptnew

def creat_pattern(dataframe, level):
  ptm=[]
  for ti in dataframe.columns.values:
    ptm.append(str.split(ti, "_")[3])
  for colname in ['Ratio']:
     print(colname)
     pattern=map_pattern(colname, ptm, dataframe, level)
  return 0

def CURa2d_replace(filename,frames, sframe):
	data=pd.DataFrame.from_csv(filename)
	data=data.replace(['---','----'],['',''])
	data.to_csv(filename+".replace")
	data=pd.DataFrame.from_csv(filename+".replace")
	data=data[data.Frame> sframe]
	Std=pd.DataFrame(columns=data.columns)
	Av=pd.DataFrame(columns=data.columns)
	for level in range(1,13):
		dlevel=data[data.Level==level]
		Av.loc[level]=dlevel.mean(skipna=True, numeric_only=True)
		Std.loc[level]=dlevel.std(skipna=True)
	print(Av.shape, Std.shape)
	Av.to_csv("Curves_a2d_av.csv")
	Std.to_csv("Curves_a2d_std.csv")
		
	return Av, Std

def Creat_ContMatrix(NCI_data, outfile):

        framelist=natsorted(set(NCI_data["Frame"].values))
        chunks=Split_data(framelist)
        #threading on
        print("Running:")
        pool = mp.Pool(processes = len(chunks))
        outid=pool.map(Creat_Matrix, chunks)
        pool.close()
        pool.join()
        print("Off")
        ContactMatrix=Merge_data(outid, ".NCI_contactID_", outfile)
        print(ContactMatrix.shape)

        return ContactMatrix





if __name__=='__main__':
	print("Help: script Curves_dataA2D.csv Curves_dataE.csv Nucplot_all.csv, pdbfile, open_in_use")
	print(sys.argv)
	curveA2D=sys.argv[1]
	curveE=sys.argv[2]
	nucplotAll=sys.argv[3]
	pdb=sys.argv[4]
	opuse=sys.argv[5]

	Tstart=time.time()

		
	
	# Definiation of knowledge-based datasets
	posset=["ARG","LYS","HIE","CYS","HID","HIP"] # positive charged amino acids
	negset=["ASP","GLU","SEP","DA","DT","DG","DC","DG8","DG9","DA3","U","DT3","DG3","DC3","DA1"] # negative charged amino acids
	negdnagro=["OP1","OP2","O1P", "O2P"]
	aroset=["PHE", "TRP", "TYR"] # aromatic amino acids
	hydset=["ALA","VAL","ILE","LEU","MET"] #hdyrophobic ac excluding aromatic ac
	pbonset=["C","O","CA","HA","N","H"] # protein backbone set
	#dbonset=["P", "OP1", "OP2", "O3'", "O5'", "C3'", "C4'","C2'", "H2'", "H2''", "C1'", "H1'", "O4'", "H4'","C5'", "H5'", "H5''"] # chemical definition of backbone
	dbonset=["P", "OP1", "OP2", "O3'", "O5'", "C3'", "C4'", "H4'","C5'", "H5'", "H5''"] # not consider the sguar group

	# new atom sets in PTM residues
	(ptm_aly, ptm_sep)= PTM_NEW(pdb)

	# define the thresholding of nocontributive contacts and salt bridge interaction
	THnic=5.0e-1
	THsbi=-1.0e-2

	########################
#	#use only the open in range frames
#	frames=list(set(pd.DataFrame.from_csv(opuse).Frame))
#	print(frames[0:10])
	
	########################
	
	
	# Classification of all interactions
	NCI_data=NCI_Classfication(nucplotAll, THsbi, THnic)

	# load classified interactions
	NCI_data=pd.DataFrame.from_csv("Nucplot_classified.csv")

	#NCI_data=NCI_data[NCI_data.Frame>50000]

	# Creat contacts identifier: P_resid_Presname_Patom_D_resid_Dresname_Datom_PTM
	Contacts=NCI_data["P_resid"].map(str)+"_"+NCI_data["P_resname"]+"_"+NCI_data["P_atom"]+"_"+NCI_data["D_resid"].map(str)+"_"+NCI_data["D_resname"]+"_"+NCI_data["D_atom"]+"_"+NCI_data["Type"]
	NCI_data["Cname"]=pd.Series(Contacts, index=Contacts.index)
	ContactID=list(natsorted(set(Contacts.values)))

	# Create a dataframe to store contactID matrix
	NCI_contactID=pd.DataFrame(columns=ContactID)
	NCI_contactID.to_csv("NCI_contactID.csv")

	# creat contact matrix
	ContactMatrix=Creat_ContMatrix(NCI_data, "NCI_contactID.csv")
	"""	
		
	##############################################
	# Average and std of contact distance
	ContactMatrix=pd.DataFrame.from_csv("NCI_contactID.csv")
	

	#Dist stores statistics of distance matrix
	Dist=pd.DataFrame(columns=ContactMatrix.columns)
	Dist.loc["Average"]=ContactMatrix.mean(skipna=True, numeric_only=True)
	Dist.loc["STD"]=ContactMatrix.std(skipna=True, numeric_only=True)
	Dist.loc["Ratio"]=ContactMatrix.count(numeric_only=True)/len(ContactMatrix.index)
	cutoff=[Dist.loc["Ratio"]>0.01]
	#print(cutoff[0][0])
	Dist.loc["RatioCut01"]=cutoff[0]
	Dist.shape
	DistT=Dist.transpose()
	DistT=DistT[DistT.RatioCut01 !=0]
	Dist_cut=DistT.transpose()
	print(Dist.shape)
	Dist_cut.to_csv("NCI_DIST_CUT.csv")
	Dist.to_csv("NCI_DIST.csv")
		

	##############################################	
	Dist=pd.DataFrame.from_csv("NCI_DIST.csv")
	
	fig_ratio=Dist.loc["Ratio"]
	fig_av=Dist.loc["Average"]
	fig_std=Dist.loc["STD"]
	fig, (ax0, ax1) = plt.subplots(2, sharex=True,figsize=(50,5))
	#fig = plt.figure() 
	gs = gridspec.GridSpec(2, 1, height_ratios=[1, 2]) 
	ax0 = plt.subplot(gs[0])
	ax0.plot(range(len(fig_ratio.index)), fig_ratio.values, 'r')
	ax1 = plt.subplot(gs[1],sharex=ax0)
	ax1.errorbar(range(len(fig_av.index)), fig_av.values, yerr=fig_std.values, fmt='o')
	# Fine-tune figure; make subplots close to each other and hide x ticks for
	# all but bottom plot.
	fig.subplots_adjust(hspace=0)
	plt.setp([a.get_xticklabels() for a in fig.axes[:-1]], visible=False)

	plt.savefig("Dist_ratio.png")
	#plt.show()

	Dist_cut=pd.DataFrame.from_csv("NCI_DIST_CUT.csv")
	creat_pattern(Dist_cut, 100)
	
		
	
	##############################################
	# Statistics of Curves data from A TO D
	#(A2D_av, A2D_std) = CURa2d_replace(curveA2D)
	
	
	"""

	##############################################
	Tend=time.time()
	print("Total Time:", Tend - Tstart)

